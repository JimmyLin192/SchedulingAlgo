%% This is file `elsarticle-template-1-num.tex',
%%
%% Copyright 2009 Elsevier Ltd
%%
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%%
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%%
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%%
%% Template article for Elsevier's document class `elsarticle'
%% with numbered style bibliographic references
%%
%% $Id: elsarticle-template-1-num.tex 149 2009-10-08 05:01:15Z rishi $
%% $URL: http://lenova.river-valley.com/svn/elsbst/trunk/elsarticle-template-1-num.tex $
%%
\documentclass[preprint,12pt]{elsarticle}

%% Use the option review to obtain double line spacing
%% \documentclass[preprint,review,12pt]{elsarticle}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
%% \documentclass[final,1p,times]{elsarticle}
%% \documentclass[final,1p,times,twocolumn]{elsarticle}
%% \documentclass[final,3p,times]{elsarticle}
%% \documentclass[final,3p,times,twocolumn]{elsarticle}
%% \documentclass[final,5p,times]{elsarticle}
%% \documentclass[final,5p,times,twocolumn]{elsarticle}

%% if you use PostScript figures in your article
%% use the graphics package for simple commands
%% \usepackage{graphics}
%% or use the graphicx package for more complicated commands
%% \usepackage{graphicx}
%% or use the epsfig package if you prefer to use the old commands
%% \usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}
%% The amsthm package provides extended theorem environments
\usepackage{amsthm}

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers after \end{frontmatter}.
\usepackage{lineno}

%% natbib.sty is loaded by default. However, natbib options can be
%% provided with \biboptions{...} command. Following options are
%% valid:

%%   round  -  round parentheses are used (default)
%%   square -  square brackets are used   [option]
%%   curly  -  curly braces are used      {option}
%%   angle  -  angle brackets are used    <option>
%%   semicolon  -  multiple citations separated by semi-colon
%%   colon  - same as semicolon, an earlier confusion
%%   comma  -  separated by comma
%%   numbers-  selects numerical citations
%%   super  -  numerical citations as superscripts
%%   sort   -  sorts multiple citations according to order in ref. list
%%   sort&compress   -  like sort, but also compresses numerical citations
%%   compress - compresses without sorting
%%
% \biboptions{comma,round}

% \biboptions{}


\journal{CS386C Dependable Computing System}

\begin{document}

\begin{frontmatter}

%% Title, authors and addresses

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for the associated footnote;
%% use the fnref command within \author or \address for footnotes;
%% use the fntext command for the associated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for the associated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
%%
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \address{Address\fnref{label3}}
%% \fntext[label3]{}

\title{A Brief Survey of Multi-Processor Scheduling For Hard Real-Time Systems}

%% use optional labels to link authors explicitly to addresses:
%% \author[label1,label2]{<author name>}
%% \address[label1]{<address>}
%% \address[label2]{<address>}

\author[UTCS]{Xin Lin}
\author[UTCS]{Xiaorong Zhu}
\author[UTCS]{Lijia Liu}

\address[UTCS]{Department of Computer Science, The University of Texas at Austin}

\begin{abstract}
%% Text of abstract
In class, both of scheduling algorithms \cite{liu1973scheduling} and priority
inheritance protocols \cite{sha1990priority} in
the context of a single processor were examined in details.  Nevertheless, the
emergence and popularity of distributed computing system gave rise to the
need to solve multi-processor scheduling and priority inheritance problems. 
As the supplementary study, this paper surveys existing scheduling algorithms in
the context of multiple processors. The very first section outlines the
background of multi-processor scheduling problems, as well as system models,
terminology, and the metrics of scheduling algorithms. After that, partitioned
scheduling and global scheduling, as the primary objects of our research, will
be fully explored. Moreover, we will also give brief sketch to the hybrid
approaches of partitioned scheduling and global scheduling. 
\end{abstract}

\begin{keyword}
System \sep Scheduling Algorithm \sep Task Management
%% keywords here, in the form: keyword \sep keyword

%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)

\end{keyword}

\end{frontmatter}

%%
%% Start line numbering here if you want
%%
\linenumbers

%% main text
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction} \label{S:1}



\subsection{Problem Defintion}

\subsection{Preview Of Related works}

\subsection{Paper Organization}
0. Background and introduction

1. System Models

2. Partitioned Scheduling

3. Global Scheduling

4. Hybrid Approach

5. Conclusion and Discussion

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{System Models} \label{S:2}
\subsection{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Partitioned Scheduling} \label{S:3}
In this section, we will review some partitioned approaches to multiprocessor real-time scheduling, and then compare their performance.
\subsection{Characteristic of Partitioned Scheduling}
Partitioned scheduling provides capability for performing parallel processing and also for automation of batch execution of multiple processes. It can improve performance by breaking down a process that works on a large data set, to multiple parallel processes that work on smaller data sets, each contains part of the original data set. The general solution involves two algorithms: one to assign tasks to processors, known as the allocation, the other to schedule tasks that are assigned to each individual processor. The partitioning strategy also requires that all occurrences of a task to be executed on the same processor.

One main advantage of partitioned scheduling is that, after the allocation of tasks to processors, we can apply the optimal real-time scheduling techniques and analyses for uni-processor systems to each individual processor. 

Comparing to the global scheduling, partitioned scheduling also has some advantages. 
\begin{itemize}
\item A task that overruns its worst-case execution time will not affect tasks on other processors.
\item There is no migration cost as each task only runs on a single processor.
\item For each processor, the run-queue is much smaller comparing to the single global queue in the global scheduling, thus the overheads of managing the run-queue can be neglected. 
\end{itemize}

However, the main disadvantage of the partitioned approach is that the allocation problem is analogous to a NP-Hard problem. 

\subsection{Rate Monotonic Next Fit Scheduling (RMNF)}
The rate-monotonic-next-fit scheduling \cite{dhall1978real} is a partitioned scheduling algorithm for multiprocessors systems. According to this algorithm, tasks are first sorted in the descending order of their request rates. The scheduling scheme is that:
\begin{enumerate}
\item Starts from the first task i, and the first processor j. 
\item Assign the task i to the processor j if j meets the requirement that together with all tasks that have been assigned to the processor j, tasks can be feasibly scheduled on processor j according to the rate-monotonic scheduling algorithm for a single processor. Otherwise, assign i to j + 1 and increase j by 1. 
\item Get the next task and repeat the previous two steps, unless there is no task left.
\end{enumerate}

Let N be the number of processors required to be feasibly schedule a set of task by the RMNF algorithm, and $N_0$ be the minimum number of processors required to feasibly schedule the same set of tasks. Then as $N_0$ approaches infinity, we can get that \cite{dhall1978real}
\begin{equation}
    2.4 \leq \frac{N}{N_0} \leq 2.67 
\end{equation}

\subsection{Rate Monotonic First-Fit Scheduling (RMFF)}
The rate-monotonic-first-fit scheduling algorithm \cite{dhall1978real} is similar to the RMNF. According to the RMFF, the tasks are first sorted in the descending order of their request rates. We will use a counter N to be the number of processors required for scheduling the given tasks. N is first initiated to 1. The scheduling scheme is that:
\begin{enumerate}
\item Starts from the first task i. 
\item Starts from the lowest-indexed processor. Assign the task i to the first processor that meets the requirement that together with all tasks that have been assigned to the processor, tasks can be feasibly scheduled on the processor according to the rate-monotonic scheduling algorithm for a single processor. If no processor with index less than N meets the requirement, increase N by 1. 
\item Get the next task and repeat the previous step, unless there is no task left.
\end{enumerate}

Similarly, the bound of the rate of the number of processors N required to be feasibly schedule the task set by this algorithm, and the minimum number of processors $N_0$ required to be feasibly schedule the same set of tasks can be obtained when $N_0$ approaches infinity: 
\begin{equation}
    2 \leq \lim_{N_0 \to \infty} \frac{N}{N_0} \leq \frac{4 \times 2^{1/3}}{1 + 2^{1/3}} \approx 2.33
\end{equation}

\subsection{Rate Monotonic Best-Fit Scheduling (RMBF)}
The rate-monotonic-best-fit scheduling \cite{oh1993tight} algorithm is based on the bin-packing heuristic. Best-Fit scheme chooses to assign tasks on a processor that can maximize the utilization of that processor. 

Similar to RMNF and RMFF, we first sort all given tasks according to non-decreasing periods. Keep a counter N to be the number of processors required for scheduling the given set of tasks. N is set to 1 at the beginning. The scheduling algorithm works like this:
\begin{enumerate}
\item Starts from the first task i. 
\item Starts from the lowest-indexed processor j. Let $k_j$ and $U_j$ denote the number of tasks already assigned to the processor j and the total utilization of the $k_j$ tasks. Let $u_i$ denote the utilization of the task i. Find the smallest-indexed processor j such that task i together with all $k_j$ tasks can be feasibly scheduled by the rate-monotonic scheduling algorithm, and $2(1 + \frac{U_j}{k_j})^{-k_j} - 1 $ be as small as possible, then assign task i to j, and set $k_j = k_j + 1$, $U_j = u_j + U_j$. If $j < m$ then set $m = j$. 
\item Get the next task and repeat the previous step, unless there is no task left.
\end{enumerate}

Similarly, the bound of rate of N and $N_0$ (with the same definitions in RMFF) can be obtained when $N_0$ approaches infinity: 
\begin{equation}
    2.3 \leq \lim_{N_0 \to \infty} \frac{N}{N_0} \leq 2 + \frac{3 - 2^{3/2}}{2(2^{1/3} - 1)} \approx 2.33
\end{equation}

\subsection{Comparison and Summary}
In this section, we had introduced the three partitioned scheduling algorithms RMNF, RMFF and RMBF. All these three algorithms require that tasks are sorted according to their non-decreasing periods/request rates. They are only applicable to be applied to the situations that the periods of incoming tasks are fixed and static. 
\begin{table}
\begin{center}
\caption{Approximation Ratios}
\label{table: app_ratio}
 \begin{tabular}{| l | l | l | l |}
    \hline
    {\bf Algorithm} & {\bf Approximation Ratio $\frac{N}{N_0}$} \\ \hline
    RMNF & 2.67 \\ \hline
    RMFF & 2.33 \\ \hline
    RMBF & 2.33 \\ \hline
 \end{tabular}
 \end{center}
\end{table} 
The performance of these three algorithms are evaluated in the approximation ratio, which is defined to be the rate of N and $N_0$, the number of processors required to be feasibly schedule a set of task by the algorithm and the minimum number of processors required to feasibly schedule the same set of tasks. As shown in the Table \ref{table: app_ratio}, RMNF has a approximation ratio as 2.67, while RMFF and RMBF have better performance.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Global Scheduling} \label{S:4}
In this section, we will dive into another branch of scheduling strategies --
global approaches to multiprocessor real-time scheduling.

\subsection{Overview}
% what is global scheduling 
Global scheduling algorithms, as its name suggests, globally schedules any
feasible periodic task set. In contrast to partitioned scheduling, global
scheduling schedules jobs and tasks in one single shared queue instead of
multiple local, dedicated queues. By this means, the automatic load balancing
and lower average response time can be achieved by global approaches. In
addition to this, global approaches also take advantages of the simpler
implementations and the existence of optimal schedulers. 

% catogries of global scheduling algorithms
Global scheduling startegies include Global Fixed-Job-Priority Scheduling,
Global Fixed-Task-Priority Scheduling, and Global Dynamic Priority Scheduling. 
% focus on global dynamic priority scheduling
Although there are various categories of global scheduling algorithms, the
focus of this paper is on the Global Dynamic Priority Scheduling. In the
following subsection, it will be chacterized in details. 

\subsection{Global Dynamic Priority Scheduling}
In this subsection, we will present our in-depth exploration to the track of
global dynamic priority scheduling algorithm. To the best of our knowledge, a
number of global dynamic priority scheduling algorithms are optimal for
periodic tasksets with explicit or implicit deadlines.
For example, Proportionate Fairness algorithm and its variants including PD,
PD$^2$, ERFair, BF, SA \cite{khemka1997optimal}, and LLREF
\cite{cho2006optimal} as well, are all optimal for offline environment.
Nevertheless, no algorithms until now are optimal to cope with online
preemptive scheduling problem, where tasksets are sporadic and multi-processor
environments are enforced.
On the other hand, despite of its optimality and dominance in theory, the
usage of global dynamic priority algorithms are limited in practice. This is
because the existence of frequent preemption and migration between tasks gives
rise to excessive overheads in potential. 

The following part of this subsection will provide brief summary of three
classic global dynamic priority scheduling algorithms. They are respectively 
Proportionate Fairness Algorithm (PFair), and Largest Local Remaining Execution
First (LLREF). 

\subsubsection{PFair}
Baruah et al \cite{baruah1996proportionate} introduced Proportionate Fairness
Algorithm. 
The Pfair class of algorithms that allow full migration and fully dynamic
priorities have been shown to be theoretically optimal -- i.e., they achieve a
schedulable utilization bound (below which all tasks meet their deadlines)
that equals the total capacity of all processors. Here are some fundamental
principles of Proportionate Fairness algorithms: 

\begin{enumerate}
    \item Timeline is divided into equal length slots. 
    \item Task period and execution time are multiples of the slot size. 
    \item Each task receives amount of slots proportional to its task
        utilization. 
\end{enumerate}

The essential part of PFair algorithms is the quantum-based optimization
defined over the lag of each task $lag(\tau_i, t)$, with the goal of
minimizing the maximum lags of all tasks $\max_t|lag(\tau_i, t)|$.
\begin{equation}
    \underbrace{lag(\tau_i, t)}_{error} = 
    \underbrace{t \cdot (\frac{c_i}{T_i})}_{fluid\ exectuion\ in [0,t)} 
    - \underbrace{allocated(\tau_i, t)}_{real\ execution\ in [0,t)}
\end{equation}
The generation of an optimal schedule is based on the above definition of
$lag$. PFair algorithm does execute all urgent tasks with $lag(\tau_i, t) > 0$
and $lag(\tau_i, t +1) \geq 0$ if $\tau_i$ executes. 
On top of that, PFair algorithm does not execute tnegru tasks, for which
$lag(\tau_i, t) < 0$ and $lag(\tau_i, t+1) \leq 0$ if $\tau_i$ does not execute.  
Besides, for other tasks, only those that have the least $t$ such that
$lag(\tau_i,t) >0$ are executed.

The PFair algorithm will assign priorities to tasks at every time slot, which
indicated itself as one of job-level dynamic priority scheduling policies. 
However, this characteristic gives rise to some issues, for example, frequent
preemptions and frequent migrations.

Proportionate Fairness algorithm, as a strong candidate for solving
resource allocation problems, has wide variety of interesting applications and
powerful theoretical support. 
For instances, Kelly et al \cite{kelly1998rate} presented its application on
the problem of rate control for communication networks.  
Application of PFair algorithm on LANs and hoc networks was fulfilled by Jiang
et al \cite{jiang2005proportional}. Besides, Bonald's paper
\cite{bonald2006queueing} provides in-depth queueing analysis over proportionate
fairness as well as max-min fairness and balanced fairness. 

\subsubsection{LLREF}
LLREF was firstly introduced by Cho et al \cite{cho2006optimal}. Similar to
PFair class of algorithms, LLREF is also based on the fluid scheduling model,
where each task executes at a constant rate at all times.
The principal idea of LLREF is that given $M$ processors,  $M$ largest local
remaining execution time tasks are selected first for every secondary event. 
This is also called the LLREF scheduling policy.
To reason over task execution behavior on multiprocessors, a novel abstraction
 called Time and Local Execution Time Domain Plane (T-L Plane) was developed.

 This algorithm divides the schedule into Time and Local execution time planes
 (TL-planes), which are determined by task deadlines. The algorithm schedules
 tasks by creating smaller “local” jobs within each TL-plane. The only
 parameters considered by the algorithm during a TL-plane are the parameters
 of the local jobs. When a TL-plane completes, the next TL-plane is started.
 The duration of each TL-plane is the amount of time between consecutive
 deadlines.

\subsection{Summary}
% advantages (comparison to partitioned scheduling)
The global scheduling paradigm has advantages over the partitioned approach. 
First of all, if tasks can join and leave the system at run-time, then it may be
necessary to reallocate tasks to processors in the partitioned approach.
In addition, the partitioned approach cannot produce optimal
real-time schedules -- one that meets all task deadlines
when task utilization demand does not exceed the total processor
capacity -- for periodic task sets, since the partitioning
problem is analogous to the bin-packing problem which is known to be NP-hard
in the strong sense. 
On top of that, in some embedded processor architectures with no cache and
simpler structures, the overhead of migration has a lower
impact on the performance. 
Finally, global scheduling can theoretically contribute to an increased
understanding of the properties and behaviors of real-time scheduling
algorithms for multiprocessors.

% disadvantages
However, the global scheduling paradigm has also several disadvantages. 
Firstly, global scheduling strategies are much more complicated to implement than
partitioned scheduling. 
In other words, for the partitioned approach, once a set of tasks are allocated
to processors, the multiprocessor real-time scheduling problem becomes a
collection of single processor real-time scheduling problems.  The ease of
programming partitioned scheduling is obvious since the single processor
scheduling problem has already been well-studied and optimal algorithms with
easy implementations already exist.
Secondly, migrating tasks at run-time means more runtime overhead in that
migrating tasks may suffer cache misses on the newly assigned processor. If
the task set is fixed and known in advanced, it is obvious that the partitioned
approach provides more appropriate solutions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Hybrid Approaches} \label{S:5}

\section{Conclusions} \label{S:6}

%% The Appendices part is started with the command \appendix;
%% appendix sections are then done as normal sections
%% \appendix

%% \section{}
%% \label{}

%% References
%%
%% Following citation commands can be used in the body text:
%% Usage of \cite is as follows:
%%   \cite{key}          ==>>  [#]
%%   \cite[chap. 2]{key} ==>>  [#, chap. 2]
%%   \citet{key}         ==>>  Author [#]

%% References with bibTeX database:

\newpage
\bibliographystyle{model1-num-names}
\bibliography{main}

%% Authors are advised to submit their bibtex database files. They are
%% requested to list a bibtex style file in the manuscript if they do
%% not want to use model1-num-names.bst.

%% References without bibTeX database:

% \begin{thebibliography}{00}

%% \bibitem must have the following form:
%%   \bibitem{key}...
%%

% \bibitem{}

% \end{thebibliography}

\end{document}

%%
%\begin{table}[h]
%\centering
%\begin{tabular}{l l l}
%\hline
%\textbf{Treatments} & \textbf{Response 1} & \textbf{Response 2}\\
%\hline
%Treatment 1 & 0.0003262 & 0.562 \\
%Treatment 2 & 0.0015681 & 0.910 \\
%Treatment 3 & 0.0009271 & 0.296 \\
%\hline
%\end{tabular}
%\caption{Table caption}
%\end{table}

%\begin{figure}[h]
%\centering\includegraphics[width=0.4\linewidth]{placeholder}
%\caption{Figure caption}
%\end{figure}

%\begin{equation}
%\label{eq:emc}
%e = mc^2
%\end{equation}

%j\begin{itemize}
%j\item Bullet point one
%j\item Bullet point two
%j\end{itemize}
%j
%j\begin{enumerate}
%j\item Numbered list item one
%j\item Numbered list item two
%j\end{enumerate}

